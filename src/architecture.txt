Architecture Overview
=====================

OnTheFly is organized around **sessions**—long-lived controllers that keep track of
training state, handle dashboard commands, and coordinate checkpoints, telemetry,
and forks/merges. The core is a framework-neutral control plane that can be driven
either by OnTheFly’s native trainer loop or by external runtimes (e.g., Lightning)
through a delegate adapter.

This document focuses on the architecture and responsibilities of the key runtime
files discussed here:

- `src/onthefly/session/base.py`
- `src/onthefly/session/external.py`
- `src/onthefly/data_explorer.py`


Sessions: Core Runtime (`src/onthefly/session/base.py`)
-------------------------------------------------------

`base.py` defines `OnTheFlySessionBase`, the shared foundation used by all session
implementations. It is framework-neutral and composes behavior through mixins.

Key responsibilities:

1) Lifecycle & Event Emission
   - Owns the session lifecycle (`before_training`, `after_training`) and emits the
     canonical event stream (`session_started`, `trainStep`, `epoch_end`,
     `trainingFinished`, log events).
   - Maintains stable run identifiers (`session_id`, `cfg.run_name`) and run
     bookkeeping (`step`, `epoch`, last validation loss, runtime LR).

2) Command Bus + Pause Gate Integration
   - Wires the command bus (`ControlBus`) and router (`CommandRouter`) plus the
     pause/resume boundary gate (`PauseGate`).
   - Runs a lightweight command-drain loop in a background thread so sessions can
     respond to dashboard commands while training continues.
   - Implements `tick()` for external runtimes: the delegate calls this at safe
     points (typically batch boundaries) so pause requests take effect without a
     mid-batch interrupt.

3) Deterministic Dataloader Policies
   - Supports reproducible sampling and pause/resume semantics by cloning loaders
     with seeded generators and/or wrapping loaders with a sampler driven by
     session epoch.
   - Offers two strategies:
       * "user" policy: preserve the user loader’s order, avoid sampler surgery.
       * managed policies: enforce stateful replay via a seeded sampler and/or
         worker seeding.
   - Reapplies determinism when loaders are swapped.

4) Evaluation: `_run_test`
   - Runs a minimal evaluation loop over `test_loader`:
       * resolves device from model/session hints
       * moves the batch to device
       * supports both "generic" loss application and "batch-aware" loss functions
         via a best-effort detection path
       * emits per-step `testStep` events and averaged test loss logs
       * preserves and restores the model’s training/eval mode around evaluation
   - Uses utilities from `data_explorer.py` to:
       * generate candidate model inputs (`model_input_candidates`)
       * normalize model output to a tensor (`ensure_tensor_output`)
       * call losses that may operate on the batch object (`_call_batch_loss`)
       * treat certain warnings as failures (`_apply_loss_with_warning_guard`)
       * extract a usable loss value from various loss return shapes (`_extract_loss_value`)

5) Checkpoint Load Fallback (External-Friendly)
   - `_load_checkpoint_into_state` attempts a safe load of session-owned state.
     External sessions can override or fall back to a framework delegate loader
     when needed.


External Runtime Session (`src/onthefly/session/external.py`)
------------------------------------------------------------

`external.py` defines `OnTheFlyExternalSession`, a session variant designed for
third-party training frameworks (Lightning, Accelerate, etc.). The external runtime
owns the training loop; the session remains responsible for control-plane behavior
and dashboard fidelity.

Key components:

1) `_LightningControlDelegate`
   - A `ControlDelegate` implementation used by the command router. It translates
     dashboard commands into session actions or framework delegate requests.
   - Handles:
       * pause: sets session paused flag and calls `delegate.request_pause(...)`
       * resume: clears paused flag and calls `delegate.request_resume()`
       * fork / merge: coordinates with the session run-management helpers
       * test: triggers session-run evaluation + checkpointing pipelines

2) `OnTheFlyExternalSession` Wiring & Runtime Bindings
   - Maintains references that mirror what a framework loop already owns:
       * `model`, `optimizer`, `scheduler`, and inferred `device`
       * optional datamodule slot for Lightning-style loader provisioning
   - `bind_runtime(...)` updates the runtime objects, resolves device, and
     instantiates device/activation telemetry monitors.

3) Framework Delegate Attachment
   - `attach_framework(delegate: FrameworkDelegate)` installs the external
     adapter and registers the pause gate as a batch-boundary hook:
       * `delegate.install_batch_boundary_hook(self.console_gate)`
   - This keeps pause/resume semantics consistent with native on-the-fly behavior
     while the framework continuously drives the actual training steps.

4) Dataloader Management + Subset Rebinding
   - Stores `train_loader`, `val_loader`, `test_loader` and remembers the original
     training dataset root for later narrowing.
   - `_rebind_train_loader_to_subset(indices)` rebuilds the training loader to
     point at a `Subset` of the original dataset, preserving important loader
     knobs (batch size, collate, drop_last, shuffle).
   - Calls `delegate.refresh_train_loader()` when the active train loader changes
     so the external runtime can pick up the new dataset view.

5) Loss Function Configuration for External Loops
   - `configure_loss_fn(loss_fn)` accepts either a `torch.nn.Module` or a callable.
   - Callables are wrapped into a small `nn.Module` to standardize invocation and
     to allow attaching lightweight metadata fields used by inspection tools:
       * `_otf_uses_batch` (a hint that a loss may consume the batch object)
       * `_otf_batch_call_cfg` (a cached calling pattern for batch-loss invocation)

6) Test + Checkpoint Integration
   - Exposes a labeled test entrypoint (`_run_labeled_test_and_ckpt`) that:
       * runs a test pass (`_run_test`)
       * forces a ring checkpoint save
       * emits a structured completion event


Data & Loss Inspection Utilities (`src/onthefly/data_explorer.py`)
-----------------------------------------------------------------

`data_explorer.py` contains the inference-side utilities used for reporting and
interactive workflows. It is designed to handle diverse user batch structures and
loss APIs while bounding memory use during large scans.

Key utilities:

1) Model Input Candidate Generation
   - `model_input_candidates(model, first, rest)` builds an ordered list of input
     candidates for `model(...)` based on:
       * the first element of a batch (commonly inputs)
       * additional batch elements (optional extras)
       * embedding-adapted variants when models expose an `embedding_model` hook
   - The result is a pruned, ordered set of candidate inputs to try for robust
     model invocation in analysis contexts.

2) Model Output Normalization
   - `ensure_tensor_output(output)` returns a tensor directly if output is already
     a tensor; otherwise attempts to locate the first tensor nested in lists,
     tuples, or dicts.

3) Batch-Aware Loss Invocation
   - `_call_batch_loss(loss_fn, model, batch)` attempts to call loss functions
     that take the full batch object (and optionally the model).
   - Supports:
       * a cached call strategy via `_otf_batch_call_cfg`
       * a best-effort search across supported call patterns when no cache exists
   - On successful invocation, caches the discovered pattern to avoid repeated
     signature probing.

4) Warning Guard for Loss Computation
   - `_apply_loss_with_warning_guard(fn)` runs a callable while converting common
     tensor shape/broadcast warnings into hard errors. This prevents silently
     accepting mismatched targets or unintended broadcasting during analysis.

5) Loss Value Extraction and Coercion
   - `_extract_loss_value(val)` pulls a usable loss tensor/value out of common
     return structures:
       * raw tensor
       * dicts containing loss keys
       * tuples/lists containing tensors
   - `_coerce_to_per_sample(val, batch_size, device)` converts scalar or vector
     loss forms into a per-sample tensor of length `batch_size`, when possible.

6) Disk-Backed Spooling for Large Scans
   - `ChunkedArraySpool` streams numeric values to a temporary file in chunks.
     It provides:
       * `append()` / `extend()` for incremental writing
       * `iter_values()` for streaming reads
       * `finish()` to materialize a Python list and clean up temp files
   - This keeps memory bounded during per-sample loss or embedding sweeps.

7) Per-Sample Loss Computation
   - `compute_per_sample_losses(...)` executes an analysis pass over a dataset or
     provided `DataLoader` to produce per-sample losses and sample indices.
   - Capabilities include:
       * optional subset selection via `indices`
       * reusing an existing loader to preserve user sampler ordering when possible
       * optional train-like semantics (`mirror_train_semantics`) for dropout/BN
       * AMP control hooks for CUDA contexts
       * returning either materialized Python lists or spools (`materialize=False`)
   - Uses the model-input candidate system and loss warning guard to robustly
     handle diverse batch formats and loss behaviors.

8) Embeddings and Clustering Helpers
   - `compute_embeddings(...)` performs a forward pass over batches to gather
     embeddings, optionally using a user-provided hook.
   - `cluster_embeddings(...)` clusters embeddings with MiniBatchKMeans when
     available, with safe fallbacks.
   - `select_hard_clusters(...)` ranks clusters by mean loss for “hard example”
     selection workflows.

9) Subset Export
   - `export_subset_table(...)` writes a compact table for selected indices
     (Parquet/Feather/CSV), with a default adapter that captures sample IDs and
     labels when present.


Run Management Helpers (`src/onthefly/mixins/run_management_mixin.py`)
---------------------------------------------------------------------

`RunManagementMixin` is composed into session classes to unify fork/merge
behavior, run naming, and subset workflows. It plugs into session lifecycle
events so actions initiated from the extension share the same primitives as the
native trainer loop.

Key responsibilities:

1) Backend step normalization
   - `_ensure_backend_step_tracker`, `_mark_backend_step_reset`, and
     `_normalize_backend_step` keep UI step counters continuous even when the
     underlying framework restarts its own counters after a reset or resume.

2) Run naming + transition records
   - `_next_run_name` lazily seeds fork/merge counters from environment
     variables so VS Code can restore numbering when a session reconnects.
   - `_switch_to_new_run` emits `runTransition`/`finalizeRun` events, writes a
     `run.json` manifest (parents, spawn metadata, hparams), resets checkpoints,
     and re-seeds progress-related session fields.

3) Train-loader subset rebinding
   - `_rebind_train_loader_to_subset` remembers the original training dataset
     and recreates `DataLoader` instances (preserving batch size, collate
     function, drop_last, shuffle flags) so forks and manual subsets can operate
     on stable dataset views.

4) Merge orchestration
   - `_merged_state_dict_from_checkpoints` loads checkpoints, materializes clone
     models, and applies SWA/Fisher/adapter merge strategies.
   - `_merge_from_checkpoints` chooses run names, calls `_switch_to_new_run`, and
     stores metadata so the dashboard can render merge provenance.

5) Fork + subset selection workflows
   - `_do_fork` handles parent checkpoint resolution, selection policies (manual
     lists, quantiles, k-means clusters, loss regions), and early cancellation
     when pause/stop flags trip.
   - `_build_features_for_selection` and `_compute_subset_losses`
     (wrapping `data_explorer.compute_per_sample_losses`) provide per-sample
     losses/embeddings used by quantile + clustering selectors. Embedding-based
     selection leverages `_run_kmeans`, `compute_embeddings`, and
     `select_hard_clusters` to isolate "hard" regions automatically.


End-to-End Runtime Flow (Relevant Portions)
-------------------------------------------

1) External runtime binds objects
   - External frameworks call `OnTheFlyExternalSession.bind_runtime(...)` to
     provide model/optimizer/scheduler/device hints and to initialize monitors.

2) Dataloaders are configured
   - External sessions accept explicit loaders or pull them from a datamodule/model.
   - Determinism policies are re-applied when loaders change.

3) Training loop proceeds in the framework
   - The framework drives forward/backward/optimizer steps.
   - At safe boundaries, the framework delegate triggers the pause gate hook and/or
     calls `session.tick()` to honor pause/resume.

4) Test and reporting pathways
   - `OnTheFlySessionBase._run_test` runs a standalone evaluation pass over the
     `test_loader`, using data_explorer helpers to interpret batches and compute loss.
   - Per-sample scans and report generation use `compute_per_sample_losses` and
     spooling to remain memory-stable on large datasets.

5) Fork/merge workflows
   - External sessions can rebuild train loaders against subsets via
     `_rebind_train_loader_to_subset(...)` and notify the framework delegate to
     refresh the loader view.


Where to Look When Debugging
----------------------------

- Test-time loss failures:
  * `src/onthefly/session/base.py::_run_test`
  * `src/onthefly/data_explorer.py::_call_batch_loss`
  * `src/onthefly/data_explorer.py::_apply_loss_with_warning_guard`

- Per-sample report failures:
  * `src/onthefly/data_explorer.py::compute_per_sample_losses`
  * candidate generation and tensor extraction utilities in the same file

- External framework integration issues:
  * `src/onthefly/session/external.py::attach_framework`
  * `_LightningControlDelegate` pause/resume/test translations
  * loader rebinding + `delegate.refresh_train_loader()` hooks
